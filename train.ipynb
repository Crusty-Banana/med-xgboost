{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_sample = 'data/processed/train_processed_sample.csv'\n",
    "train_processed_target = 'data/processed/train_processed_target.csv'\n",
    "\n",
    "test_processed_sample = 'data/processed/test_processed_sample.csv'\n",
    "test_processed_target = 'data/processed/test_processed_target.csv'\n",
    "\n",
    "validate_processed_sample = 'data/processed/validate_processed_sample.csv'\n",
    "validate_processed_target = 'data/processed/validate_processed_target.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(train_processed_sample)\n",
    "y_train = pd.read_csv(train_processed_target)\n",
    "\n",
    "X_test = pd.read_csv(test_processed_sample)\n",
    "y_test = pd.read_csv(test_processed_target)\n",
    "\n",
    "X_val = pd.read_csv(validate_processed_sample)\n",
    "y_val = pd.read_csv(validate_processed_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[15:09:13] /workspace/include/xgboost/objective.h:101: multioutput is not supported by the current objective function\nStack trace:\n  [bt] (0) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7fc5e271cbbc]\n  [bt] (1) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x5c2982) [0x7fc5e2ab1982]\n  [bt] (2) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x5c2ad9) [0x7fc5e2ab1ad9]\n  [bt] (3) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x5c92a2) [0x7fc5e2ab82a2]\n  [bt] (4) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x5cabbd) [0x7fc5e2ab9bbd]\n  [bt] (5) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x7fc5e262642f]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7fc62f1c2ff5]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7fc62f1c240a]\n  [bt] (8) /usr/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x5b6) [0x7fc62f1e5306]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m      3\u001b[0m dtest \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_test, label\u001b[38;5;241m=\u001b[39my_test)\n\u001b[1;32m      5\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softprob\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Multi-class classification with probabilities\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m'\u001b[39m: y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],  \u001b[38;5;66;03m# Number of classes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m }\n\u001b[0;32m---> 16\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mpredict(dtest)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "File \u001b[0;32m~/code/venv/lib/python3.8/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/venv/lib/python3.8/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/code/venv/lib/python3.8/site-packages/xgboost/core.py:2100\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2100\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/code/venv/lib/python3.8/site-packages/xgboost/core.py:284\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [15:09:13] /workspace/include/xgboost/objective.h:101: multioutput is not supported by the current objective function\nStack trace:\n  [bt] (0) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7fc5e271cbbc]\n  [bt] (1) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x5c2982) [0x7fc5e2ab1982]\n  [bt] (2) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x5c2ad9) [0x7fc5e2ab1ad9]\n  [bt] (3) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x5c92a2) [0x7fc5e2ab82a2]\n  [bt] (4) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x5cabbd) [0x7fc5e2ab9bbd]\n  [bt] (5) /home/LENOVO/code/venv/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x7fc5e262642f]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7fc62f1c2ff5]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7fc62f1c240a]\n  [bt] (8) /usr/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x5b6) [0x7fc62f1e5306]\n\n"
     ]
    }
   ],
   "source": [
    "# Create DMatrix for model\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multi:softprob',  # Multi-class classification with probabilities\n",
    "    'num_class': y_train.shape[1],  # Number of classes\n",
    "    'eval_metric': 'mlogloss',  # Multi-class log loss\n",
    "    'max_depth': 6,  # Maximum depth of a tree\n",
    "    'learning_rate': 0.1,  # Learning rate\n",
    "    'subsample': 0.8,  # Subsample ratio\n",
    "    'colsample_bytree': 0.8,  # Subsample ratio of columns\n",
    "    'device': 'cuda',\n",
    "}\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "y_pred_prob = bst.predict(dtest)\n",
    "\n",
    "# Evaluate the model\n",
    "logloss = log_loss(y_test, y_pred_prob)\n",
    "print(f'Log Loss: {logloss:.4f}')\n",
    "\n",
    "print('Predicted Probabilities:')\n",
    "print(pd.DataFrame(y_pred_prob, columns=[f'Class_{i}' for i in range(y.shape[1])]))\n",
    "\n",
    "# Save the model to a file\n",
    "model_filename = 'model/xgboost_model_1.json'\n",
    "bst.save_model(model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
