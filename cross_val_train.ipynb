{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.special import rel_entr\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_sample = 'data/processed/train_processed_sample1.csv'\n",
    "train_processed_target = 'data/processed/train_processed_target.csv'\n",
    "\n",
    "test_processed_sample = 'data/processed/test_processed_sample1.csv'\n",
    "test_processed_target = 'data/processed/test_processed_target.csv'\n",
    "test_processed_diff = 'data/processed/test_processed_differential_diagnosis.csv'\n",
    "\n",
    "validate_processed_sample = 'data/processed/validate_processed_sample.csv'\n",
    "validate_processed_target = 'data/processed/validate_processed_target.csv'\n",
    "validate_processed_diff = 'data/processed/validate_processed_differential_diagnosis.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_list = [5, 8, 10, 15, 20, 30]\n",
    "lr_list = [0.01, 0.03, 0.05, 0.1, 0.3, 0.4, 0.5, 0.8]\n",
    "subsam_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "colsam_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "rnd_list = [10, 15, 20, 25, 30, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(train_processed_sample)\n",
    "y_train = pd.read_csv(train_processed_target)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "X_val = pd.read_csv(validate_processed_sample)\n",
    "y_val = pd.read_csv(validate_processed_target)\n",
    "\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "y_val = y_val['PATHOLOGY'].values\n",
    "\n",
    "diff_val = pd.read_csv(validate_processed_diff)\n",
    "diff_val = diff_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m      8\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/dep\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(dep) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_lr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(lr\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_subsam\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(subsam\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_colsam\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(colsam\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_rnd\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(rnd) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(seed)\n\u001b[1;32m     10\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softprob\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Multi-class classification with probabilities\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m49\u001b[39m,  \u001b[38;5;66;03m# Number of classes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m }\n\u001b[0;32m---> 22\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrnd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Eval\u001b[39;00m\n\u001b[1;32m     25\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mpredict(dval)\n",
      "File \u001b[0;32m~/med-xgboost/venv/lib/python3.8/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/med-xgboost/venv/lib/python3.8/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/med-xgboost/venv/lib/python3.8/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    for dep in dep_list:\n",
    "        for lr in lr_list:\n",
    "            for subsam in subsam_list:\n",
    "                for colsam in colsam_list:\n",
    "                    for rnd in rnd_list:\n",
    "                        seed = random.randint(0, 100000)\n",
    "                        model_filename = \"model/dep\" + str(dep) + \"_lr\" + str(int(lr*100)) + \"_subsam\" + str(int(subsam*10)) + \"_colsam\" + str(int(colsam*10)) + \"_rnd\" + str(rnd) + \"_sed\" + str(seed)\n",
    "\n",
    "                        params = {\n",
    "                            'objective': 'multi:softprob',  # Multi-class classification with probabilities\n",
    "                            'num_class': 49,  # Number of classes\n",
    "                            'eval_metric': 'mlogloss',  # Multi-class log loss\n",
    "                            'max_depth': dep,  # Maximum depth of a tree\n",
    "                            'learning_rate': lr,  # Learning rate\n",
    "                            'subsample': subsam,  # Subsample ratio\n",
    "                            'colsample_bytree': colsam,  # Subsample ratio of columns\n",
    "                            'seed': seed,\n",
    "                            'device': 'cuda',\n",
    "                        }\n",
    "\n",
    "                        bst = xgb.train(params, dtrain, num_boost_round=rnd)\n",
    "\n",
    "                        # Eval\n",
    "                        y_pred_prob = bst.predict(dval)\n",
    "\n",
    "                        predicted_classes = np.argmax(y_pred_prob, axis=1)\n",
    "                        score = accuracy_score(y_val, predicted_classes)\n",
    "                        model_filename += \"_GTPA\" + str(int(score * 10000))\n",
    "\n",
    "                        y_pred_prob = bst.predict(dval)\n",
    "\n",
    "                        threshold = 0.01\n",
    "\n",
    "                        DDrecall = 0\n",
    "                        DDprecision = 0\n",
    "                        for i in range(len(y_pred_prob)):\n",
    "                            overlap = 0\n",
    "                            diff_num = 0 \n",
    "                            pred_num = 0\n",
    "                            for pathology in range(49):\n",
    "                                if (y_pred_prob[i][pathology] > threshold):\n",
    "                                    pred_num += 1\n",
    "                                if (diff_val[i][pathology] > threshold):\n",
    "                                    diff_num += 1\n",
    "\n",
    "                                    if (y_pred_prob[i][pathology] > threshold):\n",
    "                                        overlap += 1\n",
    "\n",
    "                            DDrecall += overlap/diff_num\n",
    "                            DDprecision += overlap/pred_num\n",
    "\n",
    "                        DDrecall /= len(y_pred_prob)\n",
    "                        DDprecision /= len(y_pred_prob)\n",
    "                        F1 = (2 * DDprecision * DDrecall) / (DDprecision + DDrecall)\n",
    "\n",
    "                        # Save model for later use\n",
    "                        model_filename += \"_F1_\" + str(int(F1 * 10000)) + \".json\"\n",
    "                        bst.save_model(model_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
