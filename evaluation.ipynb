{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.special import rel_entr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_processed_sample = 'data/processed/validate_processed_sample.csv'\n",
    "validate_processed_target = 'data/processed/validate_processed_target.csv'\n",
    "validate_processed_diff = 'data/processed/validate_processed_differential_diagnosis.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.read_csv(validate_processed_sample)\n",
    "y_val = pd.read_csv(validate_processed_target)\n",
    "\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "del X_val\n",
    "\n",
    "diff_val = pd.read_csv(validate_processed_diff)\n",
    "diff_val = diff_val.to_numpy()\n",
    "y_val = y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.Booster()\n",
    "model_filename = 'model/xgboost_model_7749.json'\n",
    "bst.load_model(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = bst.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.01\n",
    "\n",
    "DDrecall = 0\n",
    "DDprecision = 0\n",
    "for i in range(len(y_pred_prob)):\n",
    "    overlap = 0\n",
    "    diff_num = 0 \n",
    "    pred_num = 0\n",
    "    for pathology in range(49):\n",
    "        if (y_pred_prob[i][pathology] > threshold):\n",
    "            pred_num += 1\n",
    "        if (diff_val[i][pathology] > threshold):\n",
    "            diff_num += 1\n",
    "\n",
    "            if (y_pred_prob[i][pathology] > threshold):\n",
    "                overlap += 1\n",
    "    DDrecall += overlap/diff_num\n",
    "    DDprecision += overlap/pred_num\n",
    "\n",
    "DDrecall /= len(y_pred_prob)\n",
    "DDprecision /= len(y_pred_prob)\n",
    "F1 = (2 * DDprecision * DDrecall) / (DDprecision + DDrecall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21422449951684627\n",
      "0.9979935521865185\n",
      "0.35273302346517615\n"
     ]
    }
   ],
   "source": [
    "print(DDrecall)\n",
    "print(DDprecision)\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "[ True False False  True False False False False False  True False  True\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False  True False  True False\n",
      " False]\n",
      "1\n",
      "[0.0000e+00 0.0000e+00 0.0000e+00 9.9999e-01 0.0000e+00 1.0000e-06\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e-06\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 2.0000e-06 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_prob[0]>0.01)\n",
    "print(diff_val[0]>0.01)\n",
    "# print(np.argmax(y_pred_prob[0]))\n",
    "# print(np.argmax(diff_val[0]))\n",
    "print(np.sum(np.logical_and((y_pred_prob[0]>0.01), diff_val[0]>0.01)))\n",
    "\n",
    "top_indices = np.argsort(y_pred_prob[0])[-8:]\n",
    "result = np.zeros_like(y_pred_prob[0])\n",
    "result[top_indices] = y_pred_prob[0][top_indices]\n",
    "print(np.round(result, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7328234476926794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted_classes = np.argmax(diff_val, axis=1)\n",
    "score = accuracy_score(y_val, predicted_classes)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
